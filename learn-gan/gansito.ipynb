{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4ba0b14",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-10-11T04:57:27.600342Z",
     "iopub.status.busy": "2024-10-11T04:57:27.599658Z",
     "iopub.status.idle": "2024-10-11T04:57:48.141321Z",
     "shell.execute_reply": "2024-10-11T04:57:48.140381Z"
    },
    "papermill": {
     "duration": 20.549262,
     "end_time": "2024-10-11T04:57:48.143544",
     "exception": false,
     "start_time": "2024-10-11T04:57:27.594282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de GPUs disponibles: 2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "from torchinfo import summary\n",
    "\n",
    "\n",
    "import timm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import random\n",
    "from IPython.display import display\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"matplotlib\")\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Set seed\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "# torch.use_deterministic_algorithms(True)\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "# torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Global variables\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "LEARNING_RATE = 1e-4\n",
    "BATCH_SIZE = 1024\n",
    "IMAGE_SIZE = 64\n",
    "CHANNELS_IMG = 3\n",
    "Z_DIM = 100\n",
    "NUM_EPOCHS = 5\n",
    "FEATURES_CRITIC = 16\n",
    "FEATURES_GEN = 16\n",
    "CRITIC_ITERATIONS = 5\n",
    "LAMBDA_GP = 10\n",
    "\n",
    "DATA_PATH = '/kaggle/input/2-deep-learning-cs-5364-lab-1-nivel-1'\n",
    "\n",
    "N_GPU = torch.cuda.device_count() if torch.cuda.is_available() else 0\n",
    "print(f\"Número de GPUs disponibles: {N_GPU}\")\n",
    "\n",
    "CKPT_PATH = \"checkpoint.pth.tar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eff94418",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-11T04:57:48.152405Z",
     "iopub.status.busy": "2024-10-11T04:57:48.151813Z",
     "iopub.status.idle": "2024-10-11T04:57:51.702490Z",
     "shell.execute_reply": "2024-10-11T04:57:51.701437Z"
    },
    "papermill": {
     "duration": 3.557579,
     "end_time": "2024-10-11T04:57:51.704741",
     "exception": false,
     "start_time": "2024-10-11T04:57:48.147162",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(170000, 3)\n",
      "Label\n",
      "0     5000\n",
      "1     5000\n",
      "2     5000\n",
      "3     5000\n",
      "4     5000\n",
      "5     5000\n",
      "6     5000\n",
      "7     5000\n",
      "8     5000\n",
      "9     5000\n",
      "10    5923\n",
      "11    6742\n",
      "12    5958\n",
      "13    6131\n",
      "14    5842\n",
      "15    5421\n",
      "16    5918\n",
      "17    6265\n",
      "18    5851\n",
      "19    5949\n",
      "20    6000\n",
      "21    6000\n",
      "22    6000\n",
      "23    6000\n",
      "24    6000\n",
      "25    6000\n",
      "26    6000\n",
      "27    6000\n",
      "28    6000\n",
      "29    6000\n",
      "Name: count, dtype: int64\n",
      "170000\n",
      "136000 34000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Analyze dataset\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "train_dataset = pd.concat([\n",
    "    pd.read_csv(f'{DATA_PATH}/train_1.csv').assign(dataset='train_1'),\n",
    "    pd.read_csv(f'{DATA_PATH}/train_2.csv').assign(dataset='train_2'),\n",
    "    pd.read_csv(f'{DATA_PATH}/train_3.csv').assign(dataset='train_3'),\n",
    "], ignore_index=True)\n",
    "\n",
    "print(train_dataset.shape)\n",
    "\n",
    "train_dataset['ImageId'] = train_dataset['ImageId'].apply(lambda x: x + '.png' if not x.endswith('.png') else x)\n",
    "train_dataset['Path'] = train_dataset.apply(\n",
    "    lambda x: f'{DATA_PATH}/NIVEL1/NIVEL1/TRAIN/{x[\"dataset\"]}/{x[\"ImageId\"]}', axis=1\n",
    ")\n",
    "\n",
    "train_1 = train_dataset[train_dataset['dataset'] == 'train_1']\n",
    "train_2 = train_dataset[train_dataset['dataset'] == 'train_2']\n",
    "train_3 = train_dataset[train_dataset['dataset'] == 'train_3']\n",
    "\n",
    "print(train_dataset['Label'].value_counts().sort_index())\n",
    "# print(train_dataset['Label'].value_counts(normalize=True).sort_index())\n",
    "\n",
    "def split_data(data):\n",
    "    train, val = train_test_split(data, test_size=0.2, random_state=seed, stratify=data['Label'])\n",
    "    return train, val\n",
    "\n",
    "# each folder is one of MNIST, CIFAR10, FASHION MNIST\n",
    "train_1_train, train_1_val = split_data(train_1)\n",
    "train_2_train, train_2_val = split_data(train_2)\n",
    "train_3_train, train_3_val = split_data(train_3)\n",
    "\n",
    "train_df = pd.concat([train_1_train, train_2_train, train_3_train]).reset_index(drop=True)\n",
    "val_df = pd.concat([train_1_val, train_2_val, train_3_val]).reset_index(drop=True)\n",
    "\n",
    "print(len(train_dataset))\n",
    "print(len(train_df), len(val_df))\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Plot sample of each dataset\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "for i, dataset in enumerate(train_dataset['dataset'].unique()):\n",
    "    img_row = train_dataset[train_dataset['dataset'] == dataset].sample(1)\n",
    "    # print(img_row['Path'].values[0])\n",
    "    # img_path = f\"{DATA_PATH}/NIVEL1/NIVEL1/TRAIN/{img_row[2]}/{img_row[0]}\"\n",
    "    img_path = img_row['Path'].values[0]\n",
    "    img_label = img_row['Label'].values[0]\n",
    "    # print(img_path)\n",
    "    image = plt.imread(img_path)\n",
    "    axs[i].imshow(image)\n",
    "    axs[i].set_title(dataset + ' - ' + image.shape.__str__())\n",
    "    axs[i].axis('off')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a3b9e9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-11T04:57:51.715095Z",
     "iopub.status.busy": "2024-10-11T04:57:51.714607Z",
     "iopub.status.idle": "2024-10-11T04:57:51.888193Z",
     "shell.execute_reply": "2024-10-11T04:57:51.887096Z"
    },
    "papermill": {
     "duration": 0.181794,
     "end_time": "2024-10-11T04:57:51.890693",
     "exception": false,
     "start_time": "2024-10-11T04:57:51.708899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
      "\n",
      "        [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
      "\n",
      "        [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]]]), 12)\n",
      "(tensor([[[0.4039, 0.4020, 0.3980,  ..., 0.4196, 0.4196, 0.4196],\n",
      "         [0.4000, 0.3975, 0.3926,  ..., 0.4157, 0.4157, 0.4157],\n",
      "         [0.3922, 0.3887, 0.3819,  ..., 0.4078, 0.4078, 0.4078],\n",
      "         ...,\n",
      "         [0.3059, 0.3020, 0.2941,  ..., 0.3804, 0.3804, 0.3804],\n",
      "         [0.3608, 0.3608, 0.3608,  ..., 0.3804, 0.3804, 0.3804],\n",
      "         [0.3882, 0.3902, 0.3941,  ..., 0.3804, 0.3804, 0.3804]],\n",
      "\n",
      "        [[0.6235, 0.6196, 0.6118,  ..., 0.6314, 0.6314, 0.6314],\n",
      "         [0.6176, 0.6137, 0.6059,  ..., 0.6275, 0.6275, 0.6275],\n",
      "         [0.6059, 0.6020, 0.5941,  ..., 0.6196, 0.6196, 0.6196],\n",
      "         ...,\n",
      "         [0.4902, 0.4735, 0.4402,  ..., 0.5922, 0.5922, 0.5922],\n",
      "         [0.5529, 0.5461, 0.5324,  ..., 0.5922, 0.5922, 0.5922],\n",
      "         [0.5843, 0.5824, 0.5784,  ..., 0.5922, 0.5922, 0.5922]],\n",
      "\n",
      "        [[0.8510, 0.8471, 0.8392,  ..., 0.8667, 0.8667, 0.8667],\n",
      "         [0.8451, 0.8412, 0.8333,  ..., 0.8603, 0.8593, 0.8588],\n",
      "         [0.8333, 0.8294, 0.8216,  ..., 0.8475, 0.8446, 0.8431],\n",
      "         ...,\n",
      "         [0.7000, 0.6730, 0.6191,  ..., 0.8196, 0.8196, 0.8196],\n",
      "         [0.7745, 0.7603, 0.7319,  ..., 0.8196, 0.8196, 0.8196],\n",
      "         [0.8118, 0.8039, 0.7882,  ..., 0.8196, 0.8196, 0.8196]]]), 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Create dataset\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    # transforms.RandomResizedCrop(IMAGE_SIZE),\n",
    "    # transforms.RandomHorizontalFlip(p=0.5),\n",
    "    # transforms.RandomVerticalFlip(p=0.5),\n",
    "    # transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.4),\n",
    "    # TODO: CIFAR10, MNIST, FASHION MNIST Normalization\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    # transforms.RandomResizedCrop(IMAGE_SIZE),\n",
    "    # transforms.RandomHorizontalFlip(p=0.5),\n",
    "    # transforms.RandomVerticalFlip(p=0.5),\n",
    "    # transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.4),\n",
    "    # TODO: CIFAR10, MNIST, FASHION MNIST Normalization\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "\n",
    "class NivelDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_row = self.dataframe.iloc[idx]\n",
    "        # img_path = f\"{DATA_PATH}/NIVEL1/NIVEL1/TRAIN/{img_row[2]}/{img_row[0]}\"\n",
    "        img_path = img_row['Path']\n",
    "\n",
    "        image = plt.imread(img_path)\n",
    "        label = self.dataframe.iloc[idx, 1]\n",
    "\n",
    "        # * if image only have 1 channel, convert to 3 channels\n",
    "        if len(image.shape) == 2:\n",
    "            image = np.stack((image,) * 3, axis=-1)\n",
    "        # print(img_path, type(image), image.shape, label)\n",
    "\n",
    "        # * apply transformations\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "train_set = NivelDataset(train_df.sample(frac=1).reset_index(drop=True), transform=transform)\n",
    "# test_set = Nivel1Dataset(test_dataset, transform=transform)\n",
    "val_set = NivelDataset(val_df, transform=transform_val)\n",
    "\n",
    "print(train_set[0])\n",
    "# print(test_set[0])\n",
    "print(val_set[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "839885b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-11T04:57:51.900388Z",
     "iopub.status.busy": "2024-10-11T04:57:51.900071Z",
     "iopub.status.idle": "2024-10-11T04:57:59.679100Z",
     "shell.execute_reply": "2024-10-11T04:57:59.678044Z"
    },
    "papermill": {
     "duration": 7.7864,
     "end_time": "2024-10-11T04:57:59.681372",
     "exception": false,
     "start_time": "2024-10-11T04:57:51.894972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133 34\n",
      "torch.Size([1024, 3, 64, 64]) torch.Size([1024])\n",
      "torch.Size([1024, 3, 64, 64]) torch.Size([1024])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Create data loaders\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(len(train_loader), len(val_loader))\n",
    "\n",
    "img, label = next(iter(train_loader))\n",
    "print(img.shape, label.shape)\n",
    "\n",
    "for data in train_loader:\n",
    "    imgs, labels = data\n",
    "    print(imgs.shape, labels.shape)\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "451ac4f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-11T04:57:59.691897Z",
     "iopub.status.busy": "2024-10-11T04:57:59.691581Z",
     "iopub.status.idle": "2024-10-11T04:57:59.700524Z",
     "shell.execute_reply": "2024-10-11T04:57:59.699754Z"
    },
    "papermill": {
     "duration": 0.016488,
     "end_time": "2024-10-11T04:57:59.702467",
     "exception": false,
     "start_time": "2024-10-11T04:57:59.685979",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gradient_penalty(critic, real, fake, device=\"cpu\"):\n",
    "    BATCH_SIZE, C, H, W = real.shape\n",
    "    alpha = torch.rand((BATCH_SIZE, 1, 1, 1)).repeat(1, C, H, W).to(device)\n",
    "    interpolated_images = real * alpha + fake * (1 - alpha)\n",
    "\n",
    "    # Calculate critic scores\n",
    "    mixed_scores = critic(interpolated_images)\n",
    "\n",
    "    # Take the gradient of the scores with respect to the images\n",
    "    gradient = torch.autograd.grad(\n",
    "        inputs=interpolated_images,\n",
    "        outputs=mixed_scores,\n",
    "        grad_outputs=torch.ones_like(mixed_scores),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "    gradient = gradient.view(gradient.shape[0], -1)\n",
    "    gradient_norm = gradient.norm(2, dim=1)\n",
    "    gradient_penalty = torch.mean((gradient_norm - 1) ** 2)\n",
    "    return gradient_penalty\n",
    "\n",
    "\n",
    "def save_checkpoint(state, filename=\"celeba_wgan_gp.pth.tar\"):\n",
    "    print(\"=> Saving checkpoint\")\n",
    "    torch.save(state, filename)\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint, gen, disc):\n",
    "    print(\"=> Loading checkpoint\")\n",
    "    gen.load_state_dict(checkpoint['gen'])\n",
    "    disc.load_state_dict(checkpoint['disc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3550b62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-11T04:57:59.712853Z",
     "iopub.status.busy": "2024-10-11T04:57:59.712563Z",
     "iopub.status.idle": "2024-10-11T04:57:59.726701Z",
     "shell.execute_reply": "2024-10-11T04:57:59.725820Z"
    },
    "papermill": {
     "duration": 0.021824,
     "end_time": "2024-10-11T04:57:59.728747",
     "exception": false,
     "start_time": "2024-10-11T04:57:59.706923",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, channels_img, features_d):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            # input: N x channels_img x 64 x 64\n",
    "            nn.Conv2d(channels_img, features_d, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            # _block(in_channels, out_channels, kernel_size, stride, padding)\n",
    "            self._block(features_d, features_d * 2, 4, 2, 1),\n",
    "            self._block(features_d * 2, features_d * 4, 4, 2, 1),\n",
    "            self._block(features_d * 4, features_d * 8, 4, 2, 1),\n",
    "            # After all _block img output is 4x4 (Conv2d below makes into 1x1)\n",
    "            nn.Conv2d(features_d * 8, 1, kernel_size=4, stride=2, padding=0),\n",
    "        )\n",
    "\n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size,\n",
    "                stride,\n",
    "                padding,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.InstanceNorm2d(out_channels, affine=True),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.disc(x)\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, channels_noise, channels_img, features_g):\n",
    "        super(Generator, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            # Input: N x channels_noise x 1 x 1\n",
    "            self._block(channels_noise, features_g * 16, 4, 1, 0),  # img: 4x4\n",
    "            self._block(features_g * 16, features_g * 8, 4, 2, 1),  # img: 8x8\n",
    "            self._block(features_g * 8, features_g * 4, 4, 2, 1),  # img: 16x16\n",
    "            self._block(features_g * 4, features_g * 2, 4, 2, 1),  # img: 32x32\n",
    "            nn.ConvTranspose2d(\n",
    "                features_g * 2, channels_img, kernel_size=4, stride=2, padding=1\n",
    "            ),\n",
    "            # Output: N x channels_img x 64 x 64\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size,\n",
    "                stride,\n",
    "                padding,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "def initialize_weights(model):\n",
    "    # Initializes weights according to the DCGAN paper\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n",
    "            nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f40dbe66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-11T04:57:59.740100Z",
     "iopub.status.busy": "2024-10-11T04:57:59.739753Z",
     "iopub.status.idle": "2024-10-11T04:57:59.947782Z",
     "shell.execute_reply": "2024-10-11T04:57:59.946910Z"
    },
    "papermill": {
     "duration": 0.215492,
     "end_time": "2024-10-11T04:57:59.949813",
     "exception": false,
     "start_time": "2024-10-11T04:57:59.734321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (disc): Sequential(\n",
       "    (0): Conv2d(3, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2)\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (5): Conv2d(128, 1, kernel_size=(4, 4), stride=(2, 2))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Create model\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# from utils import gradient_penalty, save_checkpoint, load_checkpoint\n",
    "# from models.wgan_gp import Discriminator, Generator, initialize_weights\n",
    "\n",
    "gen = Generator(Z_DIM, CHANNELS_IMG, FEATURES_GEN).to(device)\n",
    "critic = Discriminator(CHANNELS_IMG, FEATURES_CRITIC).to(device)\n",
    "\n",
    "\n",
    "if (device.type == 'cuda') and (N_GPU > 1):\n",
    "    gen = nn.DataParallel(gen, list(range(N_GPU)))\n",
    "\n",
    "\n",
    "initialize_weights(gen)\n",
    "initialize_weights(critic)\n",
    "\n",
    "# initializate optimizer\n",
    "opt_gen = optim.Adam(gen.parameters(), lr=LEARNING_RATE, betas=(0.0, 0.9))\n",
    "opt_critic = optim.Adam(critic.parameters(), lr=LEARNING_RATE, betas=(0.0, 0.9))\n",
    "\n",
    "# for tensorboard plotting\n",
    "fixed_noise = torch.randn(32, Z_DIM, 1, 1).to(device)\n",
    "writer_real = SummaryWriter(f\"logs/GAN_MNIST/real\")\n",
    "writer_fake = SummaryWriter(f\"logs/GAN_MNIST/fake\")\n",
    "step = 0\n",
    "\n",
    "gen.train()\n",
    "critic.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6759c5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-11T04:57:59.961136Z",
     "iopub.status.busy": "2024-10-11T04:57:59.960345Z",
     "iopub.status.idle": "2024-10-11T05:50:58.169275Z",
     "shell.execute_reply": "2024-10-11T05:50:58.167690Z"
    },
    "papermill": {
     "duration": 3178.216877,
     "end_time": "2024-10-11T05:50:58.171489",
     "exception": false,
     "start_time": "2024-10-11T04:57:59.954612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 26/133 [03:26<14:53,  8.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/5] Batch 25/133                   loss D: -24.7161, loss G: 14.5011, GAN loss: -10.2150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 51/133 [06:48<11:30,  8.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/5] Batch 50/133                   loss D: -58.9397, loss G: 30.9775, GAN loss: -27.9621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 76/133 [10:16<07:56,  8.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/5] Batch 75/133                   loss D: -85.8361, loss G: 45.6967, GAN loss: -40.1394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 101/133 [13:43<04:27,  8.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/5] Batch 100/133                   loss D: -108.2838, loss G: 60.2322, GAN loss: -48.0516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 126/133 [17:07<00:58,  8.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/5] Batch 125/133                   loss D: -125.8745, loss G: 73.6916, GAN loss: -52.1829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [18:03<00:00,  8.15s/it]\n",
      " 20%|█▉        | 26/133 [01:54<08:11,  4.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] Batch 25/133                   loss D: -146.9672, loss G: 91.5526, GAN loss: -55.4146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 51/133 [03:44<06:19,  4.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] Batch 50/133                   loss D: -156.6491, loss G: 101.1491, GAN loss: -55.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 76/133 [05:35<04:20,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] Batch 75/133                   loss D: -170.7571, loss G: 113.5610, GAN loss: -57.1961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 101/133 [07:24<02:21,  4.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] Batch 100/133                   loss D: -178.5804, loss G: 123.8388, GAN loss: -54.7416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 126/133 [09:14<00:32,  4.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] Batch 125/133                   loss D: -181.3604, loss G: 131.7619, GAN loss: -49.5985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [09:46<00:00,  4.41s/it]\n",
      " 20%|█▉        | 26/133 [02:01<08:54,  4.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] Batch 25/133                   loss D: -190.2058, loss G: 147.3734, GAN loss: -42.8324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 51/133 [03:58<06:32,  4.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] Batch 50/133                   loss D: -190.7123, loss G: 160.1082, GAN loss: -30.6042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 76/133 [05:52<04:30,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] Batch 75/133                   loss D: -195.6020, loss G: 176.8415, GAN loss: -18.7605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 101/133 [07:42<02:16,  4.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] Batch 100/133                   loss D: -198.4936, loss G: 187.7233, GAN loss: -10.7703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 126/133 [09:25<00:29,  4.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] Batch 125/133                   loss D: -189.2610, loss G: 201.7988, GAN loss: 12.5378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [09:50<00:00,  4.44s/it]\n",
      " 20%|█▉        | 26/133 [01:33<06:19,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] Batch 25/133                   loss D: -187.5544, loss G: 215.1953, GAN loss: 27.6409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 51/133 [02:58<04:52,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] Batch 50/133                   loss D: -186.6380, loss G: 228.3679, GAN loss: 41.7299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 76/133 [04:24<03:24,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] Batch 75/133                   loss D: -187.5474, loss G: 227.9242, GAN loss: 40.3768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 101/133 [05:51<01:56,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] Batch 100/133                   loss D: -186.0720, loss G: 227.4395, GAN loss: 41.3674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 126/133 [07:17<00:25,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] Batch 125/133                   loss D: -175.0371, loss G: 231.7968, GAN loss: 56.7598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [07:40<00:00,  3.46s/it]\n",
      " 20%|█▉        | 26/133 [01:29<06:23,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] Batch 25/133                   loss D: -171.4162, loss G: 230.3940, GAN loss: 58.9778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 51/133 [02:54<04:56,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] Batch 50/133                   loss D: -166.8916, loss G: 227.4431, GAN loss: 60.5515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 76/133 [04:21<03:27,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] Batch 75/133                   loss D: -168.7604, loss G: 220.8016, GAN loss: 52.0412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 101/133 [05:48<01:53,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] Batch 100/133                   loss D: -166.4785, loss G: 225.3223, GAN loss: 58.8438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 126/133 [07:13<00:25,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] Batch 125/133                   loss D: -152.9933, loss G: 231.2563, GAN loss: 78.2631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [07:37<00:00,  3.44s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Train model\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "loader = train_loader\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # Target labels not needed! <3 unsupervised\n",
    "    for batch_idx, (real, _) in enumerate(tqdm(loader)):\n",
    "        real = real.to(device)\n",
    "        cur_batch_size = real.shape[0]\n",
    "\n",
    "        # Train Critic: max E[critic(real)] - E[critic(fake)]\n",
    "        # equivalent to minimizing the negative of that\n",
    "        for _ in range(CRITIC_ITERATIONS):\n",
    "            noise = torch.randn(cur_batch_size, Z_DIM, 1, 1).to(device)\n",
    "            fake = gen(noise)\n",
    "            critic_real = critic(real).reshape(-1)\n",
    "            critic_fake = critic(fake).reshape(-1)\n",
    "            gp = gradient_penalty(critic, real, fake, device=device)\n",
    "            loss_critic = (\n",
    "                -(torch.mean(critic_real) - torch.mean(critic_fake)) + LAMBDA_GP * gp\n",
    "            )\n",
    "            critic.zero_grad()\n",
    "            loss_critic.backward(retain_graph=True)\n",
    "            opt_critic.step()\n",
    "\n",
    "        # Train Generator: max E[critic(gen_fake)] <-> min -E[critic(gen_fake)]\n",
    "        gen_fake = critic(fake).reshape(-1)\n",
    "        loss_gen = -torch.mean(gen_fake)\n",
    "        gen.zero_grad()\n",
    "        loss_gen.backward()\n",
    "        opt_gen.step()\n",
    "        \n",
    "        c_loss = loss_gen + loss_critic\n",
    "        # Print losses occasionally and print to tensorboard\n",
    "        if batch_idx % 25 == 0 and batch_idx > 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch}/{NUM_EPOCHS}] Batch {batch_idx}/{len(loader)} \\\n",
    "                  loss D: {loss_critic:.4f}, loss G: {loss_gen:.4f}, GAN loss: {c_loss:.4f}\"\n",
    "            )\n",
    "\n",
    "            with torch.no_grad():\n",
    "                fake = gen(fixed_noise)\n",
    "                # take out (up to) 32 examples\n",
    "                img_grid_real = torchvision.utils.make_grid(real[:32], normalize=True)\n",
    "                img_grid_fake = torchvision.utils.make_grid(fake[:32], normalize=True)\n",
    "\n",
    "                writer_real.add_image(\"Real\", img_grid_real, global_step=step)\n",
    "                writer_fake.add_image(\"Fake\", img_grid_fake, global_step=step)\n",
    "\n",
    "            step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e4f5d22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-11T05:50:58.295276Z",
     "iopub.status.busy": "2024-10-11T05:50:58.294505Z",
     "iopub.status.idle": "2024-10-11T05:50:58.578036Z",
     "shell.execute_reply": "2024-10-11T05:50:58.576934Z"
    },
    "papermill": {
     "duration": 0.345733,
     "end_time": "2024-10-11T05:50:58.579989",
     "exception": false,
     "start_time": "2024-10-11T05:50:58.234256",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Loading checkpoint\n"
     ]
    }
   ],
   "source": [
    "save_checkpoint({\n",
    "    'gen': gen.state_dict(),\n",
    "    'disc': critic.state_dict(),\n",
    "    'gen_opt': opt_gen.state_dict(),\n",
    "    'disc_opt': opt_critic.state_dict()\n",
    "}, CKPT_PATH)\n",
    "\n",
    "\n",
    "load_checkpoint(torch.load(CKPT_PATH), gen, critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84254bc",
   "metadata": {
    "papermill": {
     "duration": 0.058641,
     "end_time": "2024-10-11T05:50:58.697110",
     "exception": false,
     "start_time": "2024-10-11T05:50:58.638469",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 9588407,
     "sourceId": 85141,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3216.855126,
   "end_time": "2024-10-11T05:51:01.683080",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-11T04:57:24.827954",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}



Hola chicos como manhiana es teoria y es la ultima semana de clase antes del Final, aprovecharemos en hacer repaso. Vamos a hacer una  revision del Examen Final de anhio pasado y entre otras cosas revisar algunos concepetos nuevos como teoria de Self-Driving, lo de NeuroAI, RNNs/LSTMs y Transformers
Como recordatorio este Viernes que viene (29 de Noviembre) es el Examen Final. Y el Lab 04 (Circuito de Carritos Autonomos) es el Viernes 6 de Diciembre.

La distribucion de preguntas para el Examen Final sera 10 puntos de Teoria, 5 de Matematica y 5 de Razonamiento Analitico


DL LSTMs
	https://utec.zoom.us/rec/play/BdSJaklvhHGAZv50l8KcXoYm0F6j5ifCRRI4RiJmMnD4IDyacfiPT-XlR7OgdPAdDlfjp2IOhTmydLFs.wJWSIorkTO2xE524

```
Cross-Validation: Baseline
Baseline en TSF -> Tomorrow = Today

Markovian Assumption
	Seq2Seq Learning

PGM: Probabilistic Graphical Models
	RNN

ResNet? es FeedForward o Recurrente?
	FeedForward. Residual no es lo mismo que Recurrente

RNN tienen caracteristica en el que la salida es la entrada en la sgte iteracion.

El Transformer es una RNN o FeedForward?
```

DL Autonomous Driving
	https://utec.zoom.us/rec/play/y5FYJsOYqGgdr96s3QfC466-BPdPjo0THAgvamStyLMcJi5k8E5swFIkIUHK0aiYxhRyM_M6fo__E-Eh.U0LG-GWLBbcZTnVX

```

```

DL Transformers
	https://utec.zoom.us/rec/play/g3jcOLVz9_Qf1n9eWLm3O8TMpLt5hIHXX3Vm5ln63dOqmwRJ4hYnGyTWUmaaF7aCT3AxUue0x0vjgMCA.InxugtMe2PJLFXq9

DL Miercoles
	https://utec.zoom.us/rec/play/OyRCsX9VqEMIGSPls_E43N_Yrqz_V-fmSuVye25uLt1mMVWd-AQipWSOqlATUH7MNSXqwil08_54bqW_.ErT4Q9oaEJGiunNu


```
Transformers
	
Fija N 97
	Attention != Transformer

Receptive Field de los Transformers > Receptive Field de las CNN

Drawbacks de Transformers
	Requieren muchas mas data que los CNN



Attention Q K V
	Attention(Q, K, V) = softmax((Q K^T) / sqrt(d_k)) V

	Q, K, V son vectores de proyeccion


Context Window / Context Size

RNN vs LSTM

	LSTM, en practica tienen mayor memoria que RNN

Necesitaron algo mas potente q una LSTM para lenguaje (son mas complicados de entrenar)

Self Attention no necesariamente es simetrico


Que es optimizable y que es Hidden State

Que utilidad tienen los Values de Q, K, V, por que no solo se usa la entrada X


Shape Bias
```


DL PreExamen
	https://utec.zoom.us/rec/play/x6XOAWYcPB07homv8O6SiK3xxcCk-ZeQOkEJpryH8zKXm3bl4WU2Sov4WelPkA7JO27xXtdASBcqpgCt.zIulbwd2dgrPytkS

```

```